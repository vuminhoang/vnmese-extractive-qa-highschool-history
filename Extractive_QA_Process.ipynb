{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4d0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_anaconda\\extractive-qa-mrc\n"
     ]
    }
   ],
   "source": [
    "#%pip install transformers==4.17.0\n",
    "#!git clone https://github.com/nguyenvulebinh/extractive-qa-mrc\n",
    "%cd extractive-qa-mrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6786c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi.ViTokenizer import tokenize\n",
    "import re, os, string\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915bb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\gpu_torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer import tokenize_function, data_collator, extract_answer\n",
    "from model.mrc_model import MRCQuestionAnswering\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b99a87",
   "metadata": {},
   "source": [
    "## Xây dựng BM25\n",
    "### Đầu vào sẽ là list[list[term]], với list[term] là list các term của 1 document\n",
    "### k1 là trọng số cho tần suất từ (TF).\n",
    "### b là trọng số kiểm soát ảnh hưởng của độ dài tài liệu đến score. Với b gần 1, tài liệu dài sẽ bị trừ điểm; b gần 0 thì ngược lại.\n",
    "\n",
    "### tf: list[dict[str,int]] - số lần xuất hiện của từ trong doc.\n",
    "### df: dict[str, int] - số doc chứa term trong tập doc.\n",
    "### idf: dict[str, float] - IDF của term\n",
    "### doc_len_: list[int] - số term trong mỗi doc\n",
    "### corpus_: list[list[str]]\n",
    "### corpus_size_: int - Số lượng doc trong tập doc\n",
    "### avg_doc_len_: float - độ dài trung bình của doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c71ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    def __init__(self, k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        tf = []\n",
    "        df = {}\n",
    "        idf = {}\n",
    "        doc_len = []\n",
    "        corpus_size = 0\n",
    "        for document in corpus:\n",
    "            corpus_size += 1\n",
    "            doc_len.append(len(document))\n",
    "\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                term_count = frequencies.get(term, 0) + 1\n",
    "                frequencies[term] = term_count\n",
    "\n",
    "            tf.append(frequencies)\n",
    "\n",
    "            for term, _ in frequencies.items():\n",
    "                df_count = df.get(term, 0) + 1\n",
    "                df[term] = df_count\n",
    "\n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "\n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.corpus_ = corpus\n",
    "        self.corpus_size_ = corpus_size\n",
    "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
    "        return self\n",
    "\n",
    "    def search(self, query):\n",
    "        scores = [self._score(query, index) for index in range(self.corpus_size_)]\n",
    "        return scores\n",
    "\n",
    "    def _score(self, query, index):\n",
    "        score = 0.0\n",
    "\n",
    "        doc_len = self.doc_len_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        for term in query:\n",
    "            if term not in frequencies:\n",
    "                continue\n",
    "\n",
    "            freq = frequencies[term]\n",
    "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
    "            denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len_)\n",
    "            score += (numerator / denominator)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e45db2",
   "metadata": {},
   "source": [
    "## Các bước tiền xử lí đưa document thành list các term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6664dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('<.*?>', '', text).strip() # xóa tag của html\n",
    "    text = re.sub('(\\s)+', r'\\1', text) # đưa nhiều dấu cách/tab/xuống dòng thành 1 dấu cách/tab/xuống dòng\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3869d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text): #Loại bỏ các dấu câu trừ gạch dưới và chuyển thành chữ thường\n",
    "    listpunctuation = string.punctuation.replace('_', '')\n",
    "    for i in listpunctuation:\n",
    "        text = text.replace(i, ' ')\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1e54bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'đây là  ví dụ'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_text('Đây.là &ví dụ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7217b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Đây là ví dụ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"<tag>    Đây là    ví dụ  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f536f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_segment(sent): #token hóa câu\n",
    "    sent = tokenize(sent.encode('utf-8').decode('utf-8'))\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f51faa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Đây là ví_dụ'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_segment('Đây là ví dụ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97ab246",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'stopwords.csv'\n",
    "data = pd.read_csv(filename, sep=\"\\t\", encoding='utf-8')\n",
    "list_stopwords = set(data['stopwords'])\n",
    "\n",
    "def remove_stopword(text): #Loại bỏ stopword\n",
    "    pre_text = []\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word not in list_stopwords:\n",
    "            pre_text.append(word)\n",
    "    text2 = ' '.join(pre_text)\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d424be3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'đây_là ví dụ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_text(\"Đây_là%ví#dụ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a13a55",
   "metadata": {},
   "source": [
    "### Gộp tất cả các file trong thư mục lưu trữ dữ liệu thành 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c67d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dir = 'D:\\_anaconda\\extractive-qa-mrc\\sgk'\n",
    "file_names = [os.path.join(context_dir, path) for path in os.listdir(context_dir)]\n",
    "\n",
    "context_all_path = 'D:\\_anaconda\\extractive-qa-mrc\\context.txt'\n",
    "\n",
    "with open(context_all_path, 'w', encoding='utf8') as combined_file:\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, 'r', encoding='utf8') as current_file:\n",
    "            content = current_file.read()\n",
    "            combined_file.write(content)\n",
    "            combined_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37ba74",
   "metadata": {},
   "source": [
    "### Tạo list các document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b634810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "doc_ids = []\n",
    "with open(context_all_path, encoding='utf-8') as f_r:\n",
    "    contents = f_r.read().strip().split('======================================================================')\n",
    "    for content in contents:\n",
    "        doc_id = content.split(' ')[0].strip()\n",
    "        if doc_id[0:2] != 'c.':\n",
    "            doc_id = 'blank'\n",
    "        content = clean_text(content)\n",
    "        content = word_segment(content)\n",
    "        content = normalize_text(content)\n",
    "        content = remove_stopword(content)\n",
    "        docs.append(content)\n",
    "        doc_ids.append(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e268d8",
   "metadata": {},
   "source": [
    "### Đưa các document thành list[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56156545",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = [[word for word in document.lower().split() if word not in list_stopwords] for document in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdc193ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['di_tích', 'lịch_sử', 'địa_danh', '…', 'xâm_lược', 'đông', 'nam', 'thực_dân', 'phương', 'tây', 'tồn_tại', 'ngày_nay', 'di_tích', 'lịch_sử', 'địa_danh', 'xâm_lược', 'đông', 'nam', 'thực_dân', 'phương', 'tây', 'tồn_tại', 'ngày_nay', 'tượng_đài_la', 'pu', 'la', 'pu', 'đảo', 'mác', 'tan', 'phi', 'lip', 'pin', 'trường', 'đại_học', 'chu', 'la', 'long', 'kon', 'thái', 'lan']\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[224])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea3788",
   "metadata": {},
   "source": [
    "### Xây dựng hàm tìm kiếm các document(context) phù hợp nhất với câu cần hỏi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2986ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, limit=3, k1=1.99, b=0.655):\n",
    "    bm25 = BM25(k1=k1, b=b)\n",
    "    bm25.fit(dictionary)\n",
    "    query_processed = clean_text(query)\n",
    "    query_processed = word_segment(query_processed)\n",
    "    query_processed = remove_stopword(normalize_text(query_processed))\n",
    "    query_processed = query_processed.split()\n",
    "\n",
    "    scores = bm25.search(query_processed)\n",
    "    scores_index = np.argsort(scores)\n",
    "    scores_index = scores_index[::-1]\n",
    "    scores.sort(reverse=True)\n",
    "    docs_score = scores[:limit]\n",
    "    context = np.array([contents[i] for i in scores_index])[:limit]\n",
    "    \n",
    "    return context, docs_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2f3712",
   "metadata": {},
   "source": [
    "## Sử dụng pretrain của nguyenvulebinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9adf2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"nguyenvulebinh/vi-mrc-large\"\n",
    "# model_checkpoint = \"nguyenvulebinh/vi-mrc-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = MRCQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94899d",
   "metadata": {},
   "source": [
    "### Xây dựng hàm xử lí các đoạn context quá dài bằng cách chia context thành nhiều đoạn context con, mỗi context con sẽ trùng nhau 1 ít"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c94b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_context(context, overlap_size, max_size=300):\n",
    "    context_words = context.split(\" \")\n",
    "    len_context = len(context_words)\n",
    "    sub_len = max_size - overlap_size\n",
    "    number_sub = (len_context - overlap_size) // sub_len + 1\n",
    "\n",
    "    sub_contexts = []\n",
    "    for i in range(number_sub):\n",
    "        start = i * sub_len\n",
    "        end = min(start + max_size, len_context)\n",
    "        sub_context = context_words[start:end]\n",
    "\n",
    "        sub_context = \" \".join(sub_context)\n",
    "\n",
    "        sub_contexts.append(sub_context)\n",
    "    return sub_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dedab9",
   "metadata": {},
   "source": [
    "### Làm sạch context đưa vào model MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc9b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_context(text):\n",
    "    text = text.lower()\n",
    "    punc = '''![]{}'\"\\<>/?@#$^&*_~'''\n",
    "\n",
    "    for ele in text:\n",
    "        if ele in punc:\n",
    "            text = text.replace(ele, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f6bc1",
   "metadata": {},
   "source": [
    "### Làm sạch câu trả lời có được từ model MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e699e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(answer):\n",
    "    if ' %' in str(answer):\n",
    "        answer = str(answer.replace(' %', '%'))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80abf36a",
   "metadata": {},
   "source": [
    "### Xây dựng hàm trả lời câu hỏi với đầu vào là câu hỏi và context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c386b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, context):\n",
    "    answers = []\n",
    "    if len(context.split(\" \")) > 295:\n",
    "        list_contexts = overlap_context(context, 50, max_size=295)\n",
    "        \n",
    "        for cont in list_contexts:\n",
    "            cont = cont.split()\n",
    "            if 'c.1' in cont[0]:\n",
    "                cont = ' '.join(cont[1:])\n",
    "            else:\n",
    "                cont = ' '.join(cont[0:])\n",
    "            cont = clean_context(cont)\n",
    "            QA_input = {\n",
    "                'question': question,\n",
    "                'context': cont\n",
    "            }\n",
    "            \n",
    "            inputs = [tokenize_function(QA_input, tokenizer)]\n",
    "            inputs_ids = data_collator(inputs, tokenizer)\n",
    "            outputs = model(**inputs_ids)\n",
    "            answer = extract_answer(inputs, outputs, tokenizer)\n",
    "            answers.append(answer)\n",
    "    else:\n",
    "        context = clean_context(context)\n",
    "        context = context.split()\n",
    "        if 'c.1' in context[0]:\n",
    "            context = ' '.join(context[1:])\n",
    "        else:\n",
    "            context = ' '.join(context[0:])\n",
    "        QA_input = {\n",
    "                'question': question,\n",
    "                'context': context\n",
    "            }\n",
    "        inputs = [tokenize_function(QA_input, tokenizer)]\n",
    "        inputs_ids = data_collator(inputs, tokenizer)\n",
    "        outputs = model(**inputs_ids)\n",
    "        answers = [extract_answer(inputs, outputs, tokenizer)]\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae97e2a",
   "metadata": {},
   "source": [
    "## Xây dựng hàm thực hiện toàn bộ quá trình: tìm kiếm các document/context tốt nhất dựa trên câu cần hỏi bằng BM25, và đưa các context tốt nhất đó cùng câu cần hỏi vào model MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "583afecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(query, limit=5, k1=1.99, b=0.655):\n",
    "    contexts = bm25_search(query, limit=limit, k1=k1, b=b)[0]\n",
    "    for context in contexts:\n",
    "        results = get_answer(query, context)\n",
    "    \n",
    "        for result in results:\n",
    "            answer = result[0]['answer']\n",
    "        \n",
    "            if len(answer) > 0:\n",
    "                if answer in context:\n",
    "                    context = context.replace(answer, answer.upper())\n",
    "                return clean_answer(answer).upper().strip(), context.strip(), [context]+[cont for cont in contexts if cont != context]\n",
    "    \n",
    "    return '-1', '-1', list(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367b159",
   "metadata": {},
   "source": [
    "## Kết quả thực nghiệm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c316ea",
   "metadata": {},
   "source": [
    "### Tạo tập test. Tập test bao gồm list câu hỏi, list câu trả lời đúng và list context chứa câu trả lời đúng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1b8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'test_question.txt'\n",
    "\n",
    "with open(test_path, 'r', encoding = 'utf-8') as file:\n",
    "    raw_test = file.read()\n",
    "    list_test = raw_test.split('======================================================================')\n",
    "    list_question = []\n",
    "    list_answer = []\n",
    "    list_context = []\n",
    "    list_doc_id = []\n",
    "\n",
    "    for i in range(len(list_test)):\n",
    "        if list_test[i]:\n",
    "            t = list_test[i].strip().split('\\n')\n",
    "            list_question.append(t[0])\n",
    "            list_answer.append(t[1])\n",
    "            list_context.append(t[2])\n",
    "            list_doc_id.append(t[2].split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2506f",
   "metadata": {},
   "source": [
    "### Xây dựng hàm tính điểm cho BM25. Điểm được tính bằng tổng của 1/j, với j là top của context đúng trong limit context tìm được"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fadb74",
   "metadata": {},
   "source": [
    "#### Ví dụ, ở câu hỏi thứ nhất, BM25 tìm ra 5 context và context chính xác nằm ở context thứ 3 của BM25 thì câu 1 sẽ được 1/3 điểm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09f87275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_accu(test_path, limit=5, k1=1.99, b=0.655):\n",
    "    file = open(test_path, 'r', encoding='utf8')\n",
    "    raw_test = file.read()\n",
    "    list_test = raw_test.split('======================================================================')\n",
    "    list_question = []\n",
    "    list_answer = []\n",
    "    list_context = []\n",
    "    list_doc_id = []\n",
    "\n",
    "    for i in range(len(list_test)):\n",
    "        if list_test[i]:\n",
    "            t = list_test[i].strip().split('\\n')\n",
    "            list_question.append(t[0])\n",
    "            list_answer.append(t[1])\n",
    "            list_context.append(t[2])\n",
    "            list_doc_id.append(t[2].split(' ')[0])\n",
    "            \n",
    "    score = 0\n",
    "    top_score = [0 for i in range(limit)]\n",
    "    list_question_error = []\n",
    "    \n",
    "    for i in range(len(list_question)):\n",
    "        result = bm25_search(list_question[i], k1=k1, b=b, limit=limit)[0]\n",
    "        error = 0\n",
    "        for j in range(len(result)):\n",
    "            doc_id_pred = result[j].strip().split()[0]\n",
    "            if doc_id_pred == list_doc_id[i]:\n",
    "                error += 1\n",
    "                top_score[j] += 1\n",
    "                score += 1/(j+1)\n",
    "            else:\n",
    "                score += 0\n",
    "        if error == 0:\n",
    "            list_question_error.append(list_question[i])\n",
    "    \n",
    "    return score, list_question_error, top_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50510f22",
   "metadata": {},
   "source": [
    "qu_err = search_accu(test_path, limit=5, k1=1.99, b=0.655)[1]\n",
    "qu_true = []\n",
    "for q in list_question:\n",
    "    if q not in qu_err:\n",
    "        qu_true.append(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78d81b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_err(list_ans):\n",
    "    count = 0\n",
    "    for ans in list_ans:\n",
    "        if ans == '-1':\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e06f0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cosine(A, B):\n",
    "    x = np.dot(A, B)\n",
    "    y = norm(A) * norm(B)\n",
    "    return x/y\n",
    "\n",
    "def bm25_search_s(query, limit=3):\n",
    "    query_processed = clean_text(query)\n",
    "    query_processed = word_segment(query_processed)\n",
    "    query_processed = remove_stopword(normalize_text(query_processed))\n",
    "    query_processed = query_processed.split()\n",
    "\n",
    "    scores = bm25.search(query_processed)\n",
    "    scores_index = np.argsort(scores)\n",
    "    scores_index = scores_index[::-1]\n",
    "\n",
    "    context = np.array([contents[i] for i in scores_index])[:limit]\n",
    "\n",
    "    return context\n",
    "\n",
    "def get_embed(batch_text):\n",
    "    batch_embedding = simCSE.encode(batch_text)\n",
    "    return [np.array(vector) for vector in batch_embedding]\n",
    "\n",
    "def clean_sem(text):\n",
    "    text = text.lower()\n",
    "    punc = '''!()[]{};:'\\,\"”“<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in punc:\n",
    "            text = text.replace(ele, \"\")\n",
    "    cleaned_text = ' '.join(text.strip().split())\n",
    "    return cleaned_text\n",
    "\n",
    "def reverse_tokenized(tokenized):\n",
    "    reversed_text = \" \".join(tokenized.split(\"_\"))\n",
    "    reversed_text.replace(\" - \", \"-\")\n",
    "    reversed_text = reversed_text.replace(\" - \", \"-\")\n",
    "    return reversed_text\n",
    "\n",
    "def overlap_splitter(input_string, max_length=256, overlap=20):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    while start < len(input_string):\n",
    "        end = start + max_length\n",
    "        segment = input_string[start:end]\n",
    "        while end < len(input_string) and not input_string[end].isspace():\n",
    "            end += 1\n",
    "        segments.append(input_string[start:end].strip())\n",
    "        start = end - overlap\n",
    "    return segments\n",
    "\n",
    "def three_sub_relevant(question, context):\n",
    "    results = []\n",
    "    question = clean_sem(question)\n",
    "    context = clean_sem(context)\n",
    "    c_tokenized = tokenize(context)\n",
    "    q_tokenized = tokenize(question)\n",
    "    chunks = overlap_splitter(c_tokenized)\n",
    "    q_embed = get_embed(q_tokenized)\n",
    "\n",
    "    if len(chunks) == 1:\n",
    "        results.append(context)\n",
    "        results.append('')\n",
    "        results.append('')\n",
    "        return results\n",
    "\n",
    "    if len(chunks) == 2:\n",
    "        results.append(reverse_tokenized(chunks[0]))\n",
    "        results.append(reverse_tokenized(chunks[1]))\n",
    "        results.append('')\n",
    "        return results\n",
    "\n",
    "    embed_chunks = []\n",
    "    for i in chunks:\n",
    "        embed_chunks.append(get_embed(i))\n",
    "    score = [cosine(q_embed, embed_part) for embed_part in embed_chunks]\n",
    "    top_3_index = np.argsort(score)[::-1][:3]\n",
    "\n",
    "    results.append(reverse_tokenized(chunks[top_3_index[0]]))\n",
    "    results.append(reverse_tokenized(chunks[top_3_index[1]]))\n",
    "    results.append(reverse_tokenized(chunks[top_3_index[2]]))\n",
    "    return results\n",
    "\n",
    "def overlap_context(context, overlap_size, max_size=300):\n",
    "    context_words = context.split(\" \")\n",
    "    len_context = len(context_words)\n",
    "    sub_len = max_size - overlap_size\n",
    "    number_sub = (len_context - overlap_size) // sub_len + 1\n",
    "\n",
    "    sub_contexts = []\n",
    "    for i in range(number_sub):\n",
    "        start = i * sub_len\n",
    "        end = min(start + max_size, len_context)\n",
    "        sub_context = context_words[start:end]\n",
    "\n",
    "        sub_context = \" \".join(sub_context)\n",
    "\n",
    "        sub_contexts.append(sub_context)\n",
    "    return sub_contexts\n",
    "\n",
    "def get_answer(question, context):\n",
    "    answers = []\n",
    "    if len(context.split(\" \")) > 300:\n",
    "        list_contexts = overlap_context(context, 50)\n",
    "\n",
    "        for cont in list_contexts:\n",
    "            QA_input = {\n",
    "                'question': question,\n",
    "                'context': cont\n",
    "            }\n",
    "\n",
    "            inputs = [tokenize_function(QA_input, tokenizer)]\n",
    "            inputs_ids = data_collator(inputs, tokenizer)\n",
    "            outputs = model(**inputs_ids)\n",
    "            answer = extract_answer(inputs, outputs, tokenizer)\n",
    "            answers.append(answer)\n",
    "    else:\n",
    "        QA_input = {\n",
    "                'question': question,\n",
    "                'context': context\n",
    "            }\n",
    "        inputs = [tokenize_function(QA_input, tokenizer)]\n",
    "        inputs_ids = data_collator(inputs, tokenizer)\n",
    "        outputs = model(**inputs_ids)\n",
    "        answers = [extract_answer(inputs, outputs, tokenizer)]\n",
    "\n",
    "    return answers\n",
    "\n",
    "def answer_from_model(question, context):\n",
    "    answer = '-1'\n",
    "    results = get_answer(question, context)\n",
    "    for result in results:\n",
    "        answer = result[0]['answer']\n",
    "    return answer\n",
    "\n",
    "def answer_bm25semantic(question):\n",
    "    question = clean_sem(question)\n",
    "    arr = bm25_search_s(question,  limit=2)\n",
    "    context1 = arr[0]\n",
    "    context2 = arr[1]\n",
    "    sub1 = three_sub_relevant(question, context1)\n",
    "    sub2 = three_sub_relevant(question, context2)\n",
    "    answer = ''\n",
    "    context = ''\n",
    "    for i in sub1:\n",
    "        a =  answer_from_model(question, i)\n",
    "        if a != '':\n",
    "            answer = a\n",
    "            context = i\n",
    "            return answer, context\n",
    "    for i in sub2:\n",
    "        b = answer_from_model(question, i)\n",
    "        if b!='':\n",
    "            answer = b\n",
    "            context = i\n",
    "        return answer, context\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d97885f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_semantic(question):\n",
    "    question = clean_sem(question)\n",
    "    arr, doc_scores = bm25_search(question, limit=2, k1=1.5, b=0.75)\n",
    "    context1 = arr[0]\n",
    "    context2 = arr[1]\n",
    "    sub1 = three_sub_relevant(question, context1)\n",
    "    sub2 = three_sub_relevant(question, context2)\n",
    "    answer = ''\n",
    "    context = ''\n",
    "    for i in sub1:\n",
    "        a = answer_from_model(question, i)\n",
    "        if a != '':\n",
    "            answer = a\n",
    "            context = i\n",
    "            return answer, context, sub1\n",
    "    for i in sub2:\n",
    "        b = answer_from_model(question, i)\n",
    "        if b != '':\n",
    "            answer = b\n",
    "            context = i\n",
    "        return answer, context, sub2\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a67c25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\ASUS/.cache\\torch\\sentence_transformers\\VoVanPhuc_sup-SimCSE-VietNamese-phobert-base. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\ASUS/.cache\\torch\\sentence_transformers\\VoVanPhuc_sup-SimCSE-VietNamese-phobert-base were not used when initializing RobertaModel: ['mlp.dense.bias', 'mlp.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "simCSE = SentenceTransformer('VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe432c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('từ ngày 4 đến ngày 11-2-1945',\n",
       " 'giới sau chiến tranh 3 phân chia thành quả chiến thắng giữa các nước thắng trận trong bối cảnh đó một hội nghị quốc tế đã được triệu tập tại ianta từ ngày 4 đến ngày 11-2-1945 với sự tham dự của nguyên thủ ba cường quốc là xtalin ph rudoven và u sớcsin',\n",
       " ['rudoven và u sớcsin',\n",
       "  'giới sau chiến tranh 3 phân chia thành quả chiến thắng giữa các nước thắng trận trong bối cảnh đó một hội nghị quốc tế đã được triệu tập tại ianta từ ngày 4 đến ngày 11-2-1945 với sự tham dự của nguyên thủ ba cường quốc là xtalin ph rudoven và u sớcsin',\n",
       "  'c122 hội nghị ianta đầu năm 1945 chiến tranh thế giới thứ hai bước vào giai đoạn kết thúc nhiều vấn đề quan trọng và cấp bách đặt ra trước các cường quốc đồng minh đó là 1 nhanh chóng đánh bại hoàn toàn các nước phát xít 2 tổ chức lại thế giới sau chiến tranh'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_semantic('Hội nghị Ianta diễn ra khi nào?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff4511",
   "metadata": {},
   "source": [
    "### Xây dựng metric cho MRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b059e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c05fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95efccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    punc = '''!()[]{};:'\\,\"”“<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in punc:\n",
    "            text = text.replace(ele, \"\")\n",
    "    cleaned_text = ' '.join(text.strip().split())\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def f1_score(predict, answer):\n",
    "    pre = clean(predict)\n",
    "    ans = clean(answer)\n",
    "    pre = set(pre.split())\n",
    "    ans = set(ans.split())\n",
    "    inter = pre.intersection(ans)\n",
    "    TP = len(pre.intersection(ans))\n",
    "    FP = len(pre - inter)\n",
    "    FN = len(ans - inter)\n",
    "    if TP == 0:\n",
    "        return 0\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    return 2/((1/precision) + (1/recall))\n",
    "\n",
    "\n",
    "def mean_f1_score(ref_list, pre_list):\n",
    "    total = 0\n",
    "    for ref, pre in zip(ref_list, pre_list):\n",
    "        total += f1_score(ref, pre)\n",
    "    mean = total / len(ref_list)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6bf24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "exact_match_metric = load(\"exact_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fa4c3",
   "metadata": {},
   "source": [
    "### Kết quả của BM25 + Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0422b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [02:00<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_semantic = []\n",
    "\n",
    "for ques in tqdm(list_question):\n",
    "    pred_semantic.append(qa_semantic(ques)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b62739d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41922370606332865"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f1_score(list_answer, pred_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42dde2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = [\" năm\", \"nước \", \" nước\", \"năm \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a1fd2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.325}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_metric.compute(references=list_answer, predictions=pred_semantic, regexes_to_ignore=ignore, ignore_case=True, ignore_punctuation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd63b36",
   "metadata": {},
   "source": [
    "### Kết quả BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddf8d68d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [07:54<00:00,  5.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['73%',\n",
       " 'B. CLINTƠN',\n",
       " 'ĐẦU NĂM 1945',\n",
       " '50 NƯỚC',\n",
       " 'IANTA',\n",
       " 'QUÂN ĐỘI MĨ',\n",
       " '13 TRIỆU NGƯỜI',\n",
       " 'NHẬT BẢN',\n",
       " '-1',\n",
       " '-1',\n",
       " 'HƠN 23 TRIỆU CỬ TRI',\n",
       " '-1',\n",
       " '94',\n",
       " 'QUÂN TA TIẾN VÀO TIẾP QUẢN HÀ NỘI',\n",
       " 'MIỀN BẮC CÓ TRÊN 85% HỘ NÔNG DÂN VỚI 70% RUỘNG ĐẤT VÀO HỢP TÁC XÃ NÔNG NGHIỆP , HƠN 8% SỐ THỢ THỦ CÔNG VÀ 45% SỐ NGƯỜI BUÔN BÁN NHỎ VÀO HỢP TÁC XÃ',\n",
       " '-1',\n",
       " '-1',\n",
       " 'VĨ TUYẾN 38',\n",
       " '-1',\n",
       " 'BÀN MÔN ĐIẾM',\n",
       " '17 NƯỚC',\n",
       " '<S> HỘI NGHỊ BAN CHẤP HÀNH TRUNG ƯƠNG ĐẢNG CỘNG SẢN ĐÔNG DƯƠNG THÁNG 7/1936 CHỦ TRƯƠNG THÀNH LẬP MẶT TRẬN NÀO ?</S> C.12.103 . HỘI NGHỊ BAN CHẤP HÀNH TRUNG ƯƠNG ĐẢNG CỘNG SẢN ĐÔNG DƯƠNG THÁNG 7-1936 THÁNG 7-1936 , HỘI NGHỊ BAN CHẤP HÀNH TRUNG ƯƠNG ĐẢNG CỘNG SẢN ĐÔNG DƯƠNG , DO LÊ HỒNG PHONG CHỦ TRÌ , HỌP Ở THƯỢNG HẢI . HỘI NGHỊ DỰA TRÊN NGHỊ QUYẾT ĐẠI HỘI LẦN THỨ VII CỦA QUỐC TẾ CỘNG SẢN , CĂN CỨ VÀO TÌNH HÌNH CỤ THỂ CỦA VIỆT NAM ĐỂ ĐỊNH RA ĐƯỜNG LỐI VÀ PHƯƠNG PHÁP ĐẤU TRANH . HỘI NGHỊ XÁC ĐỊNH : NHIỆM VỤ CHIẾN LƯỢC CỦA CÁCH MẠNG TƯ SẢN DÂN QUYỀN ĐÔNG DƯƠNG LÀ CHỐNG ĐẾ QUỐC VÀ CHỐNG PHONG KIẾN ; NHIỆM VỤ TRỰC TIẾP , TRƯỚC MẮT LÀ ĐẤU TRANH CHỐNG CHẾ ĐỘ PHẢN ĐỘNG THUỘC ĐỊA ; CHỐNG PHÁT XÍT , CHỐNG CHIẾN TRANH , ĐÒI TỰ DO , DÂN SINH , DÂN CHỦ , CƠM ÁO VÀ HÒA BÌNH . PHƯƠNG PHÁP ĐẤU TRANH LÀ KẾT HỢP CÁC HÌNH THỨC CÔNG KHAI VÀ BÍ MẬT , HỢP PHÁP VÀ BẤT HỢP PHÁP . HỘI NGHỊ CHỦ TRƯƠNG THÀNH LẬP MẶT TRẬN THỐNG NHẤT NHÂN DÂN PHẢN ĐẾ ĐÔNG DƯƠNG',\n",
       " 'PHÁI VIÊN CỦA CHÍNH PHỦ PHÁP G. GÔĐA',\n",
       " '-1',\n",
       " 'AI CẬP',\n",
       " 'THÁNG 3-1938',\n",
       " '-1',\n",
       " '333',\n",
       " 'NGÀY 23-11-1946',\n",
       " '8-9-1945',\n",
       " 'NĂM 1950',\n",
       " 'LIÊN MINH NHÂN DÂN VIỆT-LÀO',\n",
       " '-1',\n",
       " 'TƯỚNG NAVA',\n",
       " '-1',\n",
       " 'QUẢNG TRỊ',\n",
       " 'ĐÔNG NAM BỘ VÀ LIÊN KHU',\n",
       " 'NGÀY 14-12-1972',\n",
       " 'GIỮA THẾ KỈ XIX',\n",
       " 'MÁT-X CƠ-VA',\n",
       " 'ĐỨC CÙNG ÁO-HUNG VÀ I-TA-LI-A',\n",
       " 'NƯỚC NGA',\n",
       " 'COÓC-NÂY',\n",
       " 'TRAI-CỐP-XKI',\n",
       " 'CUỘC BIỂU TÌNH CỦA 9 VẠN NỮ CÔNG NHÂN Ở THỦ ĐÔ PÊ-TƠ-RÔ-GRÁT',\n",
       " 'ĐẠI VIỆT',\n",
       " 'CỔ LOA ĐÔNG ANH , HÀ NỘI',\n",
       " 'KHOẢNG CUỐI THIÊN NIÊN KỈ III TCN',\n",
       " 'GIẤY LÀM BẰNG VỎ CÂY PAPIRÚT',\n",
       " '-1',\n",
       " 'ĐẠI VIỆT',\n",
       " 'CUỐI THỜI KỲ ĐỒ ĐÁ , KHOẢNG 4 VẠN NĂM TRƯỚC ĐÂY',\n",
       " 'MEN-ĐÊ-LÊ-ÉP',\n",
       " 'THANH HÓA',\n",
       " 'MỘT CHÍNH PHỦ CÁCH MẠNG ĐƯỢC BẦU RA THEO NGUYÊN TẮC PHỔ THÔNG ĐẦU PHIẾU',\n",
       " 'NHO GIÁO',\n",
       " 'TUYÊN NGÔN-TUYÊN NGÔN CỦA ĐẢNG CỘNG SẢN',\n",
       " 'DUY TRÌ HÒA BÌNH VÀ AN NINH THẾ GIỚI . PHÁT TRIỂN MỐI QUAN HỆ HỮU NGHỊ , HỢP TÁC GIỮA CÁC NƯỚC TRÊN CƠ SỞ TÔN TRỌNG NGUYÊN TẮC BÌNH ĐẲNG VÀ QUYỀN TỰ QUYẾT CỦA CÁC DÂN TỘC',\n",
       " 'TỔNG THỐNG MĨ RU-DƠ-VEN',\n",
       " 'CHIẾN TRANH THẾ GIỚI THỨ NHẤT',\n",
       " 'THÁNG 9-1931',\n",
       " 'VŨ ĐÀI CHÍNH TRỊ',\n",
       " 'ĐẢNG CỘNG SẢN TRUNG QUỐC ĐƯỢC THÀNH LẬP',\n",
       " '-1',\n",
       " 'ĐÁNH NHANH THẮNG NHANH',\n",
       " '-1',\n",
       " 'NGUYỄN TRUNG TRỰC',\n",
       " 'QUÂN PHÁP NỔ SÚNG CHIẾM THÀNH HÀ NỘI',\n",
       " '-1',\n",
       " 'PHONG KIẾN PHƯƠNG BẮC',\n",
       " '-1',\n",
       " '-1',\n",
       " 'BỘ HÌNH THƯ-BỘ LUẬT THÀNH VĂN',\n",
       " 'NĂM 1945',\n",
       " 'LÀM THUÊ ĐỂ LẤY TIỀN CÔNG',\n",
       " 'CUỘC KHỞI NGHĨA CỦA MAI XUÂN THƯỞNG Ở BÌNH ĐỊNH',\n",
       " 'NĂM 1859',\n",
       " 'M.GAN-ĐI',\n",
       " 'CÁC SẢN PHẨM NÔNG NGHIỆP , THỦ CÔNG',\n",
       " '-1']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_answer = []\n",
    "for i in tqdm(range(len(list_question))):\n",
    "    answer = qa(list_question[i])[0]\n",
    "    pred_answer.append(answer)\n",
    "pred_answer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddf02d57",
   "metadata": {},
   "source": [
    "for i in range(len(pred_answer)):\n",
    "    print(f1_score(pred_answer[i],list_answer[i]))\n",
    "    print(clean(pred_answer[i]), \"|\", clean(list_answer[i]))\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ea74e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5537775699364573"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f1_score(pred_answer, list_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d262700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n"
     ]
    }
   ],
   "source": [
    "results1 = exact_match_metric.compute(references=list_answer, predictions=pred_answer, regexes_to_ignore=ignore, ignore_case=True, ignore_punctuation=True)\n",
    "print(round(results1[\"exact_match\"], 2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec4f280",
   "metadata": {},
   "source": [
    "def metric_for_mrc(test_path, limit=5):\n",
    "    for lim in tqdm([1, 3, 5]):\n",
    "        score_search, list_ques_err, top_score = search_accu(test_path, limit=lim, k1=1.99, b=0.655)\n",
    "        true_docs = len(list_question) - len(list_ques_err)\n",
    "        list_ques_true = []\n",
    "        for q in list_question:\n",
    "            if q not in list_ques_err:\n",
    "                list_ques_true.append(q)\n",
    "        pred_in_true = []\n",
    "        pred_in_err = []\n",
    "        ans_true = []\n",
    "        ans_err = []\n",
    "\n",
    "        for i in range(len(list_ques_true)):\n",
    "            pred_in_true.append(qa(list_ques_true[i], limit=lim, k1=1.99, b=0.655)[0])\n",
    "            index = list_question.index(list_ques_true[i])\n",
    "            ans_true.append(list_answer[index])\n",
    "        for j in range(len(list_ques_err)):\n",
    "            pred_in_err.append(qa(list_ques_err[j], limit=lim, k1=1.99, b=0.655)[0])\n",
    "            jindex = list_question.index(list_ques_err[j])\n",
    "            ans_err.append(list_answer[jindex])\n",
    "\n",
    "        false_in_true = count_err(pred_in_true)\n",
    "\n",
    "        f1_in_true = mean_f1_score(ans_true, pred_in_true)\n",
    "        f1_in_err = mean_f1_score(ans_err, pred_in_err)\n",
    "\n",
    "        ignore = [\" năm\", \"nước \", \" nước\", \"năm \"]\n",
    "        em_in_true = exact_match_metric.compute(references=ans_true, predictions=pred_in_true, regexes_to_ignore=ignore, ignore_case=True, ignore_punctuation=True)\n",
    "        em_in_err = exact_match_metric.compute(references=ans_err, predictions=pred_in_err, regexes_to_ignore=ignore, ignore_case=True, ignore_punctuation=True)\n",
    "\n",
    "        pred_ans = []\n",
    "        start = time.time()\n",
    "        for i in range(len(list_question)):\n",
    "            pred_ans.append(qa(list_question[i], limit=lim, k1=1.99, b=0.655)[0])\n",
    "\n",
    "        f1_total = mean_f1_score(list_answer, pred_ans)\n",
    "        em_total = exact_match_metric.compute(references=list_answer, predictions=pred_ans, regexes_to_ignore=ignore, ignore_case=True, ignore_punctuation=True)\n",
    "        total_time = time.time() - start\n",
    "        print('limit =', lim)\n",
    "        print(true_docs, false_in_true, (f1_in_true, em_in_true), (f1_in_err, em_in_err), (f1_total, em_total), total_time)\n",
    "        print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b977abc",
   "metadata": {},
   "source": [
    "metric_for_mrc(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
